{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abuadh/Social-Media-App/blob/main/DRUMToolsDspace7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AlbJY363rFp"
      },
      "source": [
        "# Automation Tools for DRUM Curators (DSpace7)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Contributions by:**\n",
        "\n",
        "*   Melinda Kernik, University of Minnesota Libraries (original notebook, Dspace7 revisions)\n",
        "*   Valerie Collins, University of Minnesota Libraries (original notebook)\n",
        "*   Kent Gerber, University of Minnesota Libraries, University Archives (Dspace7 revisions)\n",
        "*   Haniya Abuad, University of Minnesota (Dpace7 revisions)\n",
        "\n",
        "**Contact**: datarepo@umn.edu\n",
        "\n",
        "The code in this notebook is intended for data curators working with records associated with the [Data Repository for the University of Minnesota](https://drum.umn.edu). More information about this code can be found in the main [GitHub repository](https://github.com/mkernik/drum_tools)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg3NcwMx4Igq"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "<small>*Only the \"Start here\" section is a mandatory step in using this notebook. After this step is completed, any of the \"Create\" sections can be run in any order.*</small>\n",
        "\n",
        "1.   Start here\n",
        "  -   Create Curator Log\n",
        "  -   Create Readme File\n",
        "  -   Create XML File\n",
        "\n",
        "<small>*External resources related to these tools are linked from the following sections:*</small>\n",
        "2.   Known Issues and Limitations\n",
        "3.   Download All Files from Record"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1muaJIXn4dUA"
      },
      "source": [
        "## Start Here\n",
        "\n",
        "\n",
        "---\n",
        "Activate this notebook by running the cell below. You must have this notebok open in Colab to do this.\n",
        "\n",
        "> An input box for text will appear once the notebook has activated. Copy in the **URL** for a DRUM record into this input box, and then hit the enter key. (The handle will also work.) The notebook will now remember this link, and will use it when you run any of the code blocks below.\n",
        "\n",
        "> If you enter an incorrect value, the code below will not run, but you can enter a new value by running this starting code block again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux_pAxa83qP0"
      },
      "outputs": [],
      "source": [
        "link_url = input()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so6QvmLx5EYm",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## CREATE CURATOR LOG\n",
        "\n",
        "\n",
        "---\n",
        "Run this block of code to create a curator log that will populate with the existing information on the record. By default, this file will be saved to your Downloads folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mj24LhVo5K52"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import requests\n",
        "import math\n",
        "from string import Template\n",
        "import json\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "def convert_size(size_bytes):\n",
        "    \"\"\"Convert file size in bytes to a more human readable format\"\"\"\n",
        "\n",
        "    if size_bytes == 0:\n",
        "        return \"0B\"\n",
        "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
        "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
        "    p = math.pow(1024, i)\n",
        "    s = round(size_bytes / p, 2)\n",
        "    return \"%s %s\" % (s, size_name[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use link provided to request information from the API"
      ],
      "metadata": {
        "id": "ffpu_C3fW9Dn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28YMCvPdKJnK"
      },
      "outputs": [],
      "source": [
        "#Take the input entered by the notebook user and extract the item_uuid\n",
        "drum_url_split = link_url.split (\"/\") [-2:]\n",
        "item_uuid_test = str(drum_url_split[0])\n",
        "if item_uuid_test == \"items\":\n",
        "  item_uuid = str(drum_url_split[1])\n",
        "else:\n",
        "  resolved_url = requests.get(link_url)\n",
        "  r_new_url = resolved_url.url\n",
        "  drum_url_split = r_new_url.split (\"/\") [-2:]\n",
        "  item_uuid = str(drum_url_split[1])\n",
        "\n",
        "#Construct the link to the API endpoint\n",
        "item_api_url = \"https://conservancy.umn.edu/server/api/core/items/\" + item_uuid\n",
        "print (item_api_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOEgFoXUOgsW"
      },
      "outputs": [],
      "source": [
        "#Request information from the API\n",
        "response = requests.get(item_api_url)\n",
        "itemData = response.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5xud56U5u4t"
      },
      "source": [
        "Create variables for a few specific metadata elements (title, handle, and date) to use in the log header and log filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALabBu0f5vkN"
      },
      "outputs": [],
      "source": [
        "title = itemData['name']\n",
        "handle_uri = itemData['metadata']['dc.identifier.uri'][0]['value']\n",
        "date_split = itemData['metadata']['dc.date.available'][0]['value'].split(\"T\")\n",
        "date_available = date_split[0]\n",
        "handle_split = handle_uri.split (\"/\") [-2:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7fpUFoW6AVq"
      },
      "source": [
        "Make a list of all metadata elements available on the item API page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeTzLb-Z5_AD"
      },
      "outputs": [],
      "source": [
        "metadata_string = \"\"\n",
        "for k,v in itemData['metadata'].items():\n",
        "  for x in range(len(itemData['metadata'][k])):\n",
        "    #print (k,itemData['metadata'][k][x]['value'])\n",
        "    metadata_string += str(k) + \" : \" + str(itemData['metadata'][k][x]['value']) +\"\\n\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhLZ2_lPTTfn"
      },
      "source": [
        "Test the results of the \"metadata_string\" for loop. You can skip this step unless you want to check the metadata at this point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaMzgcvMTTfn"
      },
      "outputs": [],
      "source": [
        "#print(metadata_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE7n-jFu6f0d"
      },
      "source": [
        "Access information about bundles and file bitstreams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKQVfOW36ew-"
      },
      "outputs": [],
      "source": [
        "bundles_url = itemData['_links']['bundles']['href']\n",
        "bundles_response = requests.get(bundles_url)\n",
        "bundlesData = bundles_response.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTycDIbW6Y_W"
      },
      "source": [
        "Navigate the bundle information to get to the content files of the submission (the \"original\" bitstreams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYe2cbby6W-f"
      },
      "outputs": [],
      "source": [
        "for x in range(len(bundlesData['_embedded']['bundles'])):\n",
        "  if bundlesData['_embedded']['bundles'][x]['name'] == \"ORIGINAL\":\n",
        "    bitstreams_url = bundlesData['_embedded']['bundles'][x]['_links']['bitstreams']['href']\n",
        "print (bitstreams_url)\n",
        "\n",
        "bits_response = requests.get(bitstreams_url)\n",
        "bitstreamsData = bits_response.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxZ4FLPE6_ga"
      },
      "source": [
        "Gather information about filenames and file sizes. Look at multiple pages if necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DveywzMbTTfo"
      },
      "outputs": [],
      "source": [
        "bitstreams_string = \"\"\n",
        "file_count = 0\n",
        "for page in range(bitstreamsData['page']['totalPages']):\n",
        "    #print (page)\n",
        "    next_url = bitstreams_url + \"?page=\" + str(page)\n",
        "    response = requests.get(next_url)\n",
        "    bitstreamsDataExtra = response.json()\n",
        "    for x in range(len(bitstreamsDataExtra['_embedded']['bitstreams'])):\n",
        "        filename = bitstreamsDataExtra['_embedded']['bitstreams'][x]['name']\n",
        "        if 'dc.description' in bitstreamsDataExtra['_embedded']['bitstreams'][x]['metadata']:\n",
        "          description = bitstreamsDataExtra['_embedded']['bitstreams'][x]['metadata']['dc.description'][0]['value']\n",
        "        else:\n",
        "          description = ''\n",
        "        size = convert_size(bitstreamsDataExtra['_embedded']['bitstreams'][x]['sizeBytes'])\n",
        "        bitstreams_string += filename + \" (\" + size + \")\\n\"\n",
        "        file_count += 1\n",
        "if bitstreamsData['page']['totalElements'] == file_count:\n",
        "    print (\"Number of files counted:\" + str(file_count))\n",
        "else:\n",
        "    print (\"File count looks off! File count: \" + str(file_count) + \" Expected number = \" + str(bitstreamsData['page']['totalElements']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgCjHigc7Mvo"
      },
      "source": [
        "Add the bitstream and metadata lists to the template metadata log text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0SrmQhW7M_Z"
      },
      "outputs": [],
      "source": [
        "metadata_log_template = \"Curation log for: \" + title + \"\"\"\n",
        "Handle: \"\"\" + handle_uri + \"\"\"\n",
        "Corresponding researcher:\n",
        "Curator:\n",
        "Metadata log created: \"\"\" + str(datetime.now().strftime(\"%Y-%m-%d\")) + \" (Dataset published: \" + date_available + \")\" + \"\"\"\n",
        "\\n*************************************************\n",
        "Files received:\n",
        "*************************************************\\n\"\"\" + bitstreams_string + \"\"\"\n",
        "*************************************************\n",
        "Changes made to files:\n",
        "*************************************************\n",
        "\n",
        "**************************************************\n",
        "Metadata Changes\n",
        "**************************************************\n",
        "\n",
        "**************************************************\n",
        "Correspondence Notes\n",
        "**************************************************\n",
        "\n",
        "*************************************************\n",
        "Other issues\n",
        "*************************************************\n",
        "\n",
        "*************************************************\n",
        "Original Metadata from Author:\n",
        "*************************************************\\n\"\"\"  + metadata_string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJbr208O7cSv"
      },
      "source": [
        "Download curator log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIb8L5Zp7VIO"
      },
      "outputs": [],
      "source": [
        "metadata_filename = (str(handle_split[1]) + \"_CuratorLog_\" + str(datetime.now().strftime(\"%Y%m%d\")) + \".txt\")\n",
        "with open(metadata_filename, 'w') as f:\n",
        "  f.write(metadata_log_template)\n",
        "\n",
        "files.download(metadata_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paIHFYOS8Kui",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## CREATE README FILE\n",
        "\n",
        "\n",
        "---\n",
        "Run this block of code to create a readme file that will populate with the existing information on the record. By default, this file will be saved to your Downloads folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbrJ1Af5DV7D"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import requests\n",
        "import math\n",
        "from string import Template\n",
        "import json\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "def convert_size(size_bytes):\n",
        "    \"\"\"Convert file size in bytes to a more human readable format\"\"\"\n",
        "\n",
        "    if size_bytes == 0:\n",
        "        return \"0B\"\n",
        "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
        "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
        "    p = math.pow(1024, i)\n",
        "    s = round(size_bytes / p, 2)\n",
        "    return \"%s %s\" % (s, size_name[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use link provided to request information from the API"
      ],
      "metadata": {
        "id": "xBbLm5VYWcYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Take the input entered by the notebook user and extract the item_uuid\n",
        "drum_url_split = link_url.split (\"/\") [-2:]\n",
        "item_uuid_test = str(drum_url_split[0])\n",
        "if item_uuid_test == \"items\":\n",
        "  item_uuid = str(drum_url_split[1])\n",
        "else:\n",
        "  resolved_url = requests.get(link_url)\n",
        "  r_new_url = resolved_url.url\n",
        "  print (r_new_url)\n",
        "  drum_url_split = r_new_url.split (\"/\") [-2:]\n",
        "  item_uuid = str(drum_url_split[1])\n",
        "\n",
        "#Construct the link to the API endpoint\n",
        "item_url = \"https://conservancy.umn.edu/server/api/core/items/\" + item_uuid\n",
        "print (item_url)"
      ],
      "metadata": {
        "id": "NZpmZ_DMWSTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Request information from the API\n",
        "response = requests.get(item_url)\n",
        "itemData = response.json()"
      ],
      "metadata": {
        "id": "sBoyG4x7Wa20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "651heDf88l1A"
      },
      "source": [
        "Set up dictionary to store metadata elements\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0F-1H4P8E3p"
      },
      "outputs": [],
      "source": [
        "metadata_dict = {'readme_date': str(datetime.now().strftime(\"%Y-%m-%d\")),\n",
        "                   'author_citation':\"\", 'year_published':\"\", 'url':\"\",\n",
        "                   'title':\"\",'date_published':\"\", 'authors':\"\", 'contact_author': \"\", 'date_collected':\"\",\n",
        "                   'spatial':\"\", 'abstract': \"\", 'license_info':\"\", 'publications':\"\",\n",
        "                   'funding':\"\", 'file_list':\"\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIkbPUwo9TyA"
      },
      "source": [
        "### Gather information from the API for the Readme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1OIzOfM9fJj"
      },
      "source": [
        "Identifiers (Title, Citation, URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjTst5Bw9e4D"
      },
      "outputs": [],
      "source": [
        "metadata_dict ['title'] = itemData['name']\n",
        "\n",
        "if 'dc.description.suggestedcitation' in itemData['metadata']:\n",
        "  metadata_dict ['author_citation'] = itemData['metadata']['dc.description.suggestedcitation'][0]['value']\n",
        "else:\n",
        "  metadata_dict ['author_citation'] = ''\n",
        "\n",
        "#If the record has been assigned a DOI, use that for the recommended citation. Otherwise, use the handle.\n",
        "if 'dc.identifier.doi' in itemData['metadata']:\n",
        "    metadata_dict ['url'] = itemData['metadata']['dc.identifier.doi'][0]['value']\n",
        "else:\n",
        "  metadata_dict ['url'] = itemData['metadata']['dc.identifier.uri'][0]['value']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SnlXJbE9voE"
      },
      "source": [
        "Authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KQaGMyf9T7E"
      },
      "outputs": [],
      "source": [
        "#Retrieve the last name of the contact person to be used in the filename\n",
        "contact_name = itemData['metadata']['dc.contributor.contactname'][0]['value']\n",
        "contact_split = contact_name.split (\",\") [:]\n",
        "###add logic for if the name was not enter last name, first name?\n",
        "contact_lastname = contact_split[0].replace(\" \", \"_\")\n",
        "\n",
        "contact_email = itemData['metadata']['dc.contributor.contactemail'][0]['value']\n",
        "\n",
        "try:\n",
        "  contact_author_string = \"\\tAuthor Contact: \" + contact_split[1] + \" \" + contact_split[0] + \" (\" + contact_email + \")\"\n",
        "except:\n",
        "  contact_author_string = \"\\tAuthor Contact: \" + contact_name + \" (\" + contact_email + \")\"\n",
        "metadata_dict ['contact_author'] = contact_author_string\n",
        "\n",
        "authors_list = []\n",
        "for x in range(len(itemData['metadata']['dc.contributor.author'])):\n",
        "  authors_list.append(itemData['metadata']['dc.contributor.author'][x]['value'])\n",
        "\n",
        "author_string = \"\"\n",
        "for author in authors_list:\n",
        "    # Check if the author name has a comma\n",
        "    if \",\" in author:\n",
        "    #Rearrange author name to be First Last instead of Last, First\n",
        "      author_split = author.split (\",\") [:]\n",
        "      author_firstLast = author_split[1] + \" \" + author_split[0]\n",
        "    else:\n",
        "        author_firstLast = author\n",
        "\n",
        "    #If the author is the contact person, add their email address. If not, leave email blank.\n",
        "    if author == contact_name:\n",
        "        author_string += \"\\n\\tName: \" + author_firstLast + \"\\n\\tInstitution:\\n\\tEmail: \" + contact_email + \"\\n\\tORCID: {orcid}\\n\\n\"\n",
        "    else:\n",
        "        author_string += \"\\n\\tName: \" + author_firstLast + \"\\n\\tInstitution:\\n\\tEmail:\\n\\tORCID: {orcid}\\n\\n\"\n",
        "metadata_dict ['authors'] = author_string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "johd_KuMTTfp"
      },
      "source": [
        "Test author string results (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtR_s5i_TTfp"
      },
      "outputs": [],
      "source": [
        "#print(author_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUI_es9d9x5x"
      },
      "source": [
        "Dates (Date published, year published, date collected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMhuFFig931p"
      },
      "outputs": [],
      "source": [
        "#Split the date field and use only YYYYMMDD, not exact time\n",
        "date_split = itemData['metadata']['dc.date.available'][0]['value'].split(\"T\")\n",
        "metadata_dict ['date_published'] = date_split[0]\n",
        "#Isolate the year published to use in the Readme filename\n",
        "year_split = date_split[0].split(\"-\")\n",
        "year_published = year_split[0]\n",
        "metadata_dict ['year_published'] = year_published\n",
        "\n",
        "date_collected_dict = {}\n",
        "if 'dc.date.collectedbegin' in itemData['metadata'] and 'dc.date.collectedend' in itemData['metadata']:\n",
        "    date_collected_dict['begin'] = itemData['metadata']['dc.date.collectedbegin'][0]['value']\n",
        "    date_collected_dict['end'] = itemData['metadata']['dc.date.collectedend'][0]['value']\n",
        "else:\n",
        "    print (\"No valid date collection range provided\")\n",
        "\n",
        "## Add together multiple Dspace fields to be used in one section of the readme\n",
        "if date_collected_dict:\n",
        "  metadata_dict ['date_collected'] = str(date_collected_dict['begin']) + \" to \" + str(date_collected_dict['end'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLeLTOgf98l5"
      },
      "source": [
        "Descriptive fields (Abstract and funding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRhmPpkJ98z5"
      },
      "outputs": [],
      "source": [
        "metadata_dict ['abstract'] = itemData['metadata']['dc.description.abstract'][0]['value']\n",
        "\n",
        "if 'dc.description.sponsorship' in itemData['metadata']:\n",
        "    funders_string = \"\"\n",
        "    for x in range(len(itemData['metadata']['dc.description.sponsorship'])):\n",
        "      funders_string += \"\\t\" + itemData['metadata']['dc.description.sponsorship'][x]['value'] + \"\\n\"\n",
        "    metadata_dict ['funding'] = funders_string\n",
        "else:\n",
        "    print (\"No funding information provided\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVIeFGBhsz7o"
      },
      "source": [
        "Rights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_sXs5-0TTfq"
      },
      "outputs": [],
      "source": [
        "rights_dict = {}\n",
        "rights_string = ''\n",
        "if 'dc.rights' in itemData['metadata'] and 'dc.rights.uri' in itemData['metadata']:\n",
        "    rights_string = itemData['metadata']['dc.rights'][0]['value'] + \" (\" + itemData['metadata']['dc.rights.uri'][0]['value'] + \")\"\n",
        "elif 'dc.rights' in itemData['metadata'] and 'dc.rights.uri' not in itemData['metadata']:\n",
        "    rights_string = itemData['metadata']['dc.rights'][0]['value']\n",
        "\n",
        "metadata_dict ['license_info'] = rights_string\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAcD8Y8ts6M5"
      },
      "source": [
        "Related Publications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDUkWgTgs8Ow"
      },
      "outputs": [],
      "source": [
        "###Is this element no longer included in Dspace7 or is it just missing for this specific item?  Test it against an example!\n",
        "try:\n",
        "  publication_string = \"\"\n",
        "  for x in range(len(itemData['metadata']['dc.relation.isreferencedby'])):\n",
        "    publication_string += itemData['metadata']['dc.relation.isreferencedby'][x]['value'] + \"\\n\\n\"\n",
        "  metadata_dict ['publications'] = publication_string\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4fOybXHtnWQ"
      },
      "source": [
        "File List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsFLEPHwXp0N"
      },
      "outputs": [],
      "source": [
        "#Get the API endpoint for the bitstreams list\n",
        "bundles_url = itemData['_links']['bundles']['href']\n",
        "response = requests.get(bundles_url)\n",
        "bundlesData = response.json()\n",
        "\n",
        "for x in range(len(bundlesData['_embedded']['bundles'])):\n",
        "  if bundlesData['_embedded']['bundles'][x]['name'] == \"ORIGINAL\":\n",
        "    bitstreams_url = bundlesData['_embedded']['bundles'][x]['_links']['bitstreams']['href']\n",
        "print (bitstreams_url)\n",
        "\n",
        "response = requests.get(bitstreams_url)\n",
        "bitstreamsData = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kztq1nY7TTfr"
      },
      "outputs": [],
      "source": [
        "#Make the file list, paginating through multiple pages if necessary\n",
        "file_list_string = \"\"\n",
        "file_count = 0\n",
        "for page in range(bitstreamsData['page']['totalPages']):\n",
        "    #print (page)\n",
        "    next_url = bitstreams_url + \"?page=\" + str(page)\n",
        "    response = requests.get(next_url)\n",
        "    bitstreamsDataExtra = response.json()\n",
        "    for x in range(len(bitstreamsDataExtra['_embedded']['bitstreams'])):\n",
        "      if 'dc.description' in bitstreamsDataExtra['_embedded']['bitstreams'][x]['metadata']:\n",
        "        file_list_string += (\"\\tFilename: \" + bitstreamsDataExtra['_embedded']['bitstreams'][x]['name'] +\" \\n\\tShort description: \" + bitstreamsDataExtra['_embedded']['bitstreams'][x]['metadata']['dc.description'][0]['value'] + \"\\n\\n\")\n",
        "      else:\n",
        "        file_list_string += (\"\\tFilename: \" + bitstreamsDataExtra['_embedded']['bitstreams'][x]['name'] +\" \\n\\tShort description:\\n\\n\")\n",
        "      file_count += 1\n",
        "\n",
        "metadata_dict ['file_list'] = file_list_string\n",
        "\n",
        "if bitstreamsData['page']['totalElements'] == file_count:\n",
        "    print (\"Number of files counted:\" + str(file_count))\n",
        "else:\n",
        "    print (\"File count looks off! File count: \" + str(file_count) + \" Expected number = \" + str(bitstreamsData['page']['totalElements']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCpOswEKwKim"
      },
      "source": [
        "### Add information to the Readme Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L7wQvQW_6US"
      },
      "source": [
        "Insert metadata elements from the submission into the template readme text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEMNz-0bnC0J"
      },
      "outputs": [],
      "source": [
        "readme_template = Template(\n",
        "\"\"\"This readme.txt file was generated on ${readme_date} by <Name>\n",
        "Recommended citation for the data: ${author_citation}\\n\n",
        "-------------------\n",
        "GENERAL INFORMATION\n",
        "-------------------\\n\n",
        "1. Title of Dataset: ${title}\\n\n",
        "2. Author Information\\n\\n${contact_author}\\n${authors}\n",
        "3. Date published or finalized for release: ${date_published}\\n\\n\n",
        "4. Date of data collection: ${date_collected}\\n\\n\n",
        "5. Geographic location of data collection (where was data collected?): ${spatial}\\n\\n\n",
        "6. Information about funding sources that supported the collection of the data:\\n${funding}\\n\n",
        "7. Overview of the data (abstract):\\n${abstract}\\n\\n\\n\\n\n",
        "--------------------------\n",
        "SHARING/ACCESS INFORMATION\n",
        "--------------------------\\n\n",
        "1. Licenses/restrictions placed on the data: ${license_info}\\n\n",
        "2. Links to publications that cite or use the data:\\n${publications}\n",
        "3. Was data derived from another source?\n",
        "\\tIf yes, list source(s):\\n\n",
        "4. Terms of Use: Data Repository for the U of Minnesota (DRUM) By using these files, users agree to the Terms of Use. https://conservancy.umn.edu/pages/policies/#drum-terms-of-use\\n\\n\\n\\n\n",
        "---------------------\n",
        "DATA & FILE OVERVIEW\n",
        "---------------------\\n\n",
        "${file_list}\\n\n",
        "2. Relationship between files:\\n\\n\n",
        "--------------------------\n",
        "METHODOLOGICAL INFORMATION\n",
        "--------------------------\\n\n",
        "1. Description of methods used for collection/generation of data:\\n\\n\n",
        "2. Methods for processing the data: <describe how the submitted data were generated from the raw or collected data>\\n\\n\n",
        "3. Instrument- or software-specific information needed to interpret the data:\\n\\n\n",
        "4. Standards and calibration information, if appropriate:\\n\\n\n",
        "5. Environmental/experimental conditions:\\n\\n\n",
        "6. Describe any quality-assurance procedures performed on the data:\\n\\n\n",
        "7. People involved with sample collection, processing, analysis and/or submission:\\n\\n\\n\\n\"\"\")\n",
        "\n",
        "#Replace variables in the template with the information from the metadata dictionary\n",
        "readme_string = readme_template.substitute(metadata_dict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJo5oTuOAL9q"
      },
      "source": [
        "Add a data_specific section to the readme for each spreadsheet file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN0ocdyynVxH"
      },
      "outputs": [],
      "source": [
        "#Make a list of all \"Original\" bitstream items with \".csv\" or \".xlsx\" in the name\n",
        "spreadsheets = []\n",
        "data_specific_string = \"\"\n",
        "for x in range(len(bitstreamsData['_embedded']['bitstreams'])):\n",
        "  if '.csv' in bitstreamsData['_embedded']['bitstreams'][x]['name']:\n",
        "    spreadsheets.append(bitstreamsData['_embedded']['bitstreams'][x]['name'])\n",
        "  #Will pick up a range of Excel formats including .xls, .xlsx, and .xlsm\n",
        "  if '.xls' in bitstreamsData['_embedded']['bitstreams'][x]['name']:\n",
        "    spreadsheets.append(bitstreamsData['_embedded']['bitstreams'][x]['name'])\n",
        "\n",
        "#If there are no files with .csv or .xls extensions in the submission, add a\n",
        "#placeholder \"[FILENAME]\" so that there will be one example section\n",
        "if not spreadsheets:\n",
        "    spreadsheets.append(\"[FILENAME]\")\n",
        "\n",
        "for item in spreadsheets:\n",
        "    data_specific_string += \"\"\"-----------------------------------------\n",
        "DATA-SPECIFIC INFORMATION FOR: \"\"\" + item + \"\"\"\\n-----------------------------------------\\n\n",
        "1. Number of variables:\\n\n",
        "2. Number of cases/rows:\\n\n",
        "3. Missing data codes:\\n\n",
        "\\tCode/symbol\\tDefinition\n",
        "\\tCode/symbol\\tDefinition\\n\n",
        "4. Variable List\\n\n",
        "\\tA. Name:\n",
        "\\t   Description:\n",
        "\\t\\tValue labels if appropriate\\n\n",
        "\\tB. Name:\n",
        "\\t   Description:\n",
        "\\t\\tValue labels if appropriate\\n\\n\\n\\n\"\"\"\n",
        "\n",
        "#Add the data-specific section(s) onto the end of the readme\n",
        "readme_full_string = readme_string + data_specific_string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W03Bt3mVyoVO"
      },
      "source": [
        "### Download Readme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4ISOtvuAfuC"
      },
      "source": [
        "Create the file name using contact person's last name and the year the submission was published. If contact person has not been identified create a file name with just the year published."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFdkUG9_naAd"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  readme_filename = (\"Readme_\" + contact_lastname + \"_\" + year_published + \".txt\")\n",
        "except:\n",
        "  readme_filename = (\"Readme_\" + year_published + \".txt\")\n",
        "  print (\"The name given for the contact author did not exactly match any of the names in the author list. Their contact info will need to be added to the Readme manually.\")\n",
        "\n",
        "#Generate the Readme\n",
        "with open(readme_filename, 'w') as f:\n",
        "  f.write(readme_full_string)\n",
        "\n",
        "files.download(readme_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdhPrYrsBJoY",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## CREATE DataCite XML FILE\n",
        "\n",
        "\n",
        "---\n",
        "Run this block of code to create an XML file that is formatted in the DataCite metadata schema, based on the information on the record. This file will be saved in an XML format in your Downloads folder, and will need to be uploaded to DataCite to create a DOI for the record.\n",
        "\n",
        "> [Instructions for uploading the file to DataCite](https://docs.google.com/document/d/16CVkUWrRRStqErDS_L5DRoAaLOEZlAoJBtiiOKFCirE/edit#)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwAqN0_WELLA"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import requests\n",
        "import math\n",
        "from string import Template\n",
        "import json\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "def convert_size(size_bytes):\n",
        "    \"\"\"Convert file size in bytes to a more human readable format\"\"\"\n",
        "\n",
        "    if size_bytes == 0:\n",
        "        return \"0B\"\n",
        "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
        "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
        "    p = math.pow(1024, i)\n",
        "    s = round(size_bytes / p, 2)\n",
        "    return \"%s %s\" % (s, size_name[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use link provided to request information from the API"
      ],
      "metadata": {
        "id": "cRgAu3X6YO_S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDKJR5dUTTfs"
      },
      "outputs": [],
      "source": [
        "#Take the input entered by the notebook user and extract the item_uuid\n",
        "drum_url_split = link_url.split (\"/\") [-2:]\n",
        "item_uuid_test = str(drum_url_split[0])\n",
        "if item_uuid_test == \"items\":\n",
        "  item_uuid = str(drum_url_split[1])\n",
        "else:\n",
        "  resolved_url = requests.get(link_url) #when Dspace7 is live the handle url should resolve to the new uuid-based url\n",
        "  r_new_url = resolved_url.url\n",
        "  drum_url_split = r_new_url.split (\"/\") [-2:]\n",
        "  item_uuid = str(drum_url_split[1])\n",
        "\n",
        "#Construct the link to the API endpoint\n",
        "item_api_url = \"https://conservancy.umn.edu/server/api/core/items/\" + item_uuid\n",
        "print (item_api_url)\n",
        "\n",
        "#successfully tested the if-else block above with the link redirect May 8, 2024\n",
        "# used this input url for handle version - https://conservancystage.lib.umn.edu/handle/11299/252448\n",
        "# resolved url should be - https://conservancystage.lib.umn.edu/items/2ba9c02a-0885-4907-ae1a-33eb657282b6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ2ZhIH_TTfs"
      },
      "outputs": [],
      "source": [
        "#Request information from the API\n",
        "response = requests.get(item_api_url)\n",
        "itemData = response.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj3QObKRG_kN"
      },
      "source": [
        "Identifiers (Title and link)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nc8VaA3vG_tY"
      },
      "outputs": [],
      "source": [
        "title = itemData['name']\n",
        "alt_id = itemData['metadata']['dc.identifier.uri'][0]['value']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR_cRvIqH1XK"
      },
      "source": [
        "Authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmh3-K3pH1f6"
      },
      "outputs": [],
      "source": [
        "authors_list =[]\n",
        "for x in range(len(itemData['metadata']['dc.contributor.author'])):\n",
        "  authors_list.append(itemData['metadata']['dc.contributor.author'][x]['value'])\n",
        "\n",
        "author_string = \"\"\n",
        "for author in authors_list:\n",
        "    #print (author)\n",
        "    #Rearrange author name to be First Last instead of Last, First\n",
        "    author_split = author.split (\",\") [:]\n",
        "    author_first = author_split[1]\n",
        "    author_last = author_split[0].strip()\n",
        "    #loop through authors and append each new XML <creator> block to author_string\n",
        "    author_string += \"\"\"\n",
        "<creator>\n",
        "  <creatorName nameType=\"Personal\">\"\"\" + author + \"\"\"</creatorName>\n",
        "  <givenName>\"\"\" + author_first + \"\"\"</givenName>\n",
        "  <familyName>\"\"\" + author_last + \"\"\"</familyName>\n",
        "</creator>\"\"\"\n",
        "# There is a way to add affiliation within the creator tags in Datacite Metadata schema\n",
        "#It would go under <familyName> and above <creator>\n",
        "# <affiliation affiliationIdentifier=\"https://ror.org/017zqws13\" affiliationIdentifierScheme=\"ROR\" schemeURI=\"https://ror.org\">University of Minnesota</affiliation>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvmAb-z0Krei"
      },
      "source": [
        "Dates (Publication year and Date available)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxsZDBYbIu0X"
      },
      "outputs": [],
      "source": [
        "###Should this be calculated differently?\n",
        "publication_year = str(datetime.now().strftime(\"%Y\"))\n",
        "\n",
        "date_available = itemData['metadata']['dc.date.available'][0]['value']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-6Z6q5JTfXC"
      },
      "source": [
        "Subjects\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1vtajLcTfiC"
      },
      "outputs": [],
      "source": [
        "subjects_list = []\n",
        "if 'dc.subject' in itemData['metadata']:\n",
        "    for x in range(len(itemData['metadata']['dc.subject'])):\n",
        "      subjects_list.append(itemData['metadata']['dc.subject'][x]['value'])\n",
        "else:\n",
        "    print (\"No subjects provided.\")\n",
        "\n",
        "#format <subject> block if subjects exist\n",
        "subject_string = \"\"\n",
        "if bool(subjects_list):\n",
        "  subjects = \"\"\n",
        "  for subject in subjects_list:\n",
        "    subjects += \"\"\"\n",
        "  <subject>\"\"\" + subject + \"\"\"</subject> \"\"\"\n",
        "    #add subject blocks to outer tags\n",
        "    subject_string = \"\"\"\n",
        "<subjects>\"\"\" + subjects + \"\"\"\\n</subjects>\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ct0H8gXPHcN"
      },
      "source": [
        "Descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWVoPWxgPHm8"
      },
      "outputs": [],
      "source": [
        "###Add controls if these values aren't present\n",
        "abstract_string = \"\"\n",
        "if 'dc.description.abstract' in itemData['metadata']:\n",
        "    abstract = itemData['metadata']['dc.description.abstract'][0]['value']\n",
        "    abstract_string = \"\"\"\n",
        "<description descriptionType=\"Abstract\">\"\"\" + abstract + \"\"\"</description>\"\"\"\n",
        "\n",
        "technical_desc_string = \"\"\n",
        "if 'dc.description' in itemData['metadata']:\n",
        "    technical_description = itemData['metadata']['dc.description'][0]['value']\n",
        "    technical_desc_string = \"\"\"\n",
        "<description descriptionType=\"TechnicalInfo\">\"\"\"+technical_description+\"\"\"</description>\"\"\"\n",
        "\n",
        "#if abstract or description element exists, then build the description block\n",
        "if abstract_string != \"\" or technical_desc_string != \"\":\n",
        "  description_string = \"\"\"\n",
        "<descriptions>\"\"\" + abstract_string + technical_desc_string + \"\"\"\n",
        "</descriptions>\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpT5rXyWQgHk"
      },
      "source": [
        "Rights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caYfkOKzQR0D"
      },
      "outputs": [],
      "source": [
        "###Is there any situation in which we might have multiple values for \"rights\"?  At the moment this expects that there will be only one.\n",
        "###License text and URI must be present to build the rights block\n",
        "rights_string = \"\"\n",
        "if 'dc.rights' in itemData['metadata'] and 'dc.rights.uri' in itemData['metadata']:\n",
        "    license_text = itemData['metadata']['dc.rights'][0]['value']\n",
        "    license_url = itemData['metadata']['dc.rights.uri'][0]['value']\n",
        "    rights_string = \"\"\"\n",
        "<rightsList>\n",
        "  <rights rightsURI=\\\"\"\"\"+license_url+\"\"\"\\\">\"\"\"+license_text+\"\"\"</rights>\n",
        "</rightsList>\"\"\"\n",
        "else:\n",
        "    print (\"Unable to construct a full rights block.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNJjhlJGF4G3"
      },
      "source": [
        "Add values to the DataCite Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgCuHEpwF4Tf"
      },
      "outputs": [],
      "source": [
        "datacite_schema = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
        "<resource xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://datacite.org/schema/kernel-4\" xsi:schemaLocation=\"http://datacite.org/schema/kernel-4 https://schema.datacite.org/meta/kernel-4.4/metadata.xsd\">\n",
        "<identifier identifierType=\"DOI\"></identifier>\n",
        "<creators> \"\"\" + author_string + \"\"\"\n",
        "</creators>\n",
        "<titles>\n",
        "  <title>\"\"\" + title + \"\"\"</title>\n",
        "</titles>\n",
        "<publisher>Data Repository for the University of Minnesota (DRUM)</publisher>\n",
        "<publicationYear>\"\"\" + publication_year + \"\"\"</publicationYear>\n",
        "<resourceType resourceTypeGeneral=\"Dataset\"/>\"\"\" + subject_string + \"\"\"\n",
        "<dates>\n",
        "  <date dateType=\"Available\">\"\"\" + date_available + \"\"\"</date>\n",
        "</dates>\n",
        "<alternateIdentifiers>\n",
        "  <alternateIdentifier alternateIdentifierType=\"Handle\">\"\"\" + alt_id + \"\"\"</alternateIdentifier>\n",
        "</alternateIdentifiers>\n",
        "<sizes/>\n",
        "<formats/>\n",
        "<version/>\"\"\" + rights_string + description_string + \"\"\"\n",
        "</resource>\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXzxW_q0WOvv"
      },
      "source": [
        "Download the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lNxYS_XVcM2"
      },
      "outputs": [],
      "source": [
        "handle_split = alt_id.split (\"/\") [-2:]\n",
        "schema_file_name = (str(handle_split[1]) + \"_doi_xml.xml\")\n",
        "with open(schema_file_name, 'w') as f:\n",
        "  f.write(datacite_schema)\n",
        "\n",
        "files.download(schema_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Known Issues and Limitations\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "DRUM curators can find a full list of known issues and limitations with these tools for our workflows in [this Google Drive document](https://docs.google.com/document/d/1qK53v7_k43M9pWDCw2e2cLF18lGL8U9LhBr0QU2MhME/).\n",
        "\n",
        "If you encounter any errors or have requests for new functionality, please add them to the document!"
      ],
      "metadata": {
        "id": "SLXD93h5vgJU"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "so6QvmLx5EYm",
        "UdhPrYrsBJoY"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}